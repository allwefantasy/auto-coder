# 002 - Adding and Modifying Code with AutoCoder

In practice, AutoCoder is best suited for code modification, as its most fundamental function is to generate a prompt for large models with source code, documents you specify, information gathered by search engines, and your requirements.

Additionally, it's important to correct a common misconception: AutoCoder does not create a website or a large project in one sentence. We are here to help R&D or product teams iterate products more quickly.

However, let's start from scratch, with nothing in the project. Now, we will use AutoCoder to create a web server.

```yml
source_dir: /tmp/t-py
target_file: /home/winubuntu/projects/ByzerRawCopilot/output.txt 

model: qianwen_chat
model_max_length: 2000
model_max_input_length: 6000
anti_quota_limit: 5

search_engine: bing
search_engine_token: ENV {{BING_SEARCH_TOKEN}}

## Execute the prompt generated by auto-coder
execute: true
## Extract the code from the prompt generated by auto-coder
## and overwrite the source code
auto_merge: true

project_type: py

query: >
  Create a web service using FastAPI in /tmp/t-py/server/server.py.
  The service's root path should return "Hello, World!".
```

Note that we have enabled the `auto_merge` parameter here. This parameter will modify your project, so it's best to use it with caution. If this parameter is not enabled, you can find the generated code in the `target_file` and manually copy and paste it.

Execute the following:

```shell

auto-coder --file ./examples/from-zero-to-hero/002_fastapi_hello_word.yml
```

The log is quite simple:

```
2024-03-21 17:55:08.944 | INFO     | autocoder.dispacher.actions.action:process_content:225 - Auto merge the code...
2024-03-21 17:55:08.945 | INFO     | autocoder.common.code_auto_merge:merge_code:51 - Upsert path: /tmp/t-py/server/server.py
2024-03-21 17:55:08.945 | INFO     | autocoder.common.code_auto_merge:merge_code:55 - Merged 1 files into the project.
```

Result:

```
(byzerllm-dev) (base) winubuntu@winubuntu:/tmp/t-py$ tree
.
└── server
    └── server.py

1 directory, 1 file
```

Run the code:

```
(byzerllm-dev) (base) winubuntu@winubuntu:/tmp/t-py$ python /tmp/t-py/server/server.py
INFO:     Started server process [1333520]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000  (Press CTRL+C to quit)
INFO:     127.0.0.1:33516 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:33516 - "GET /favicon.ico HTTP/1.1" 404 Not Found
```

Visit:

![](./images/image4.png)

Successfully done.

Now, let's modify the code.

```yml
source_dir: /tmp/t-py
target_file: /home/winubuntu/projects/ByzerRawCopilot/output.txt 

model: qianwen_chat
model_max_length: 2000
model_max_input_length: 6000
anti_quota_limit: 5

search_engine: bing
search_engine_token: ENV {{BING_SEARCH_TOKEN}}

## Execute the prompt generated by auto-coder
execute: true
## Extract the code from the prompt generated by auto-coder
## and overwrite the source code
auto_merge: true

project_type: py

query: >
  Modify the port in server.py to 9001
```

Execute the following:

```shell

auto-coder --file ./examples/from-zero-to-hero/002_fastapi_modify_port.yml
```

At this point, when you open server.py, you can see that the port has been changed to 9001.

```python
from fastapi import FastAPI

# Create a FastAPI application instance
app = FastAPI()

# Define the GET request handler for the root path, returning "Hello, World!"
@app.get("/")
def read_root():
    return {"message": "Hello, World!"}

if __name__ == "__main__":
    # Start the web service, port changed to 9001
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=9001)
```

You might wonder why I could directly mention modifying server.py without writing the full path this time. It's because there are Python files in the project now, providing context, so the large model can automatically infer it, and you don't need to write the full path.

That's it for today's content. In the next issue, we will explore how AutoCoder can help you with programming when you don't have access to a large model API, or if your API version of a large model is too weak, and you only have web versions like Kimi/GPT4.

Here's a spoiler:

1. AutoCoder is responsible for generating prompts; you can drag and drop files into the web version of the large model.

2. Where AutoCoder needs to use a large model, it will ask you, and at that point, you can paste the results into the web version and then paste the results back, helping AutoCoder complete the entire process.