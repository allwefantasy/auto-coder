import pytest
import tempfile
import shutil
import os
from unittest.mock import MagicMock, patch
from autocoder.common.pruner.context_pruner import PruneContext
from autocoder.common import AutoCoderArgs, SourceCode
from autocoder.sdk import get_llm, init_project_if_required
from autocoder.common.tokens import count_string_tokens


class TestPruneContextExtractStrategy:
    """Test suite for PruneContext extract strategy"""

    @pytest.fixture
    def temp_test_dir(self):
        """æä¾›ä¸€ä¸ªä¸´æ—¶çš„ã€æµ‹è¯•åè‡ªåŠ¨æ¸…ç†çš„ç›®å½•"""
        # ä¿å­˜åŸå§‹å·¥ä½œç›®å½•
        original_cwd = os.getcwd()
        temp_dir = tempfile.mkdtemp()
        try:
            yield temp_dir
        finally:
            # ç¡®ä¿æ¢å¤åˆ°åŸå§‹ç›®å½•ï¼Œå³ä½¿å‡ºç°å¼‚å¸¸
            try:
                os.chdir(original_cwd)
            except OSError:
                # å¦‚æœåŸå§‹ç›®å½•ä¹Ÿä¸å­˜åœ¨ï¼Œåˆ™åˆ‡æ¢åˆ°ç”¨æˆ·ä¸»ç›®å½•
                os.chdir(os.path.expanduser("~"))
            # åˆ é™¤ä¸´æ—¶ç›®å½•
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)

    @pytest.fixture
    def mock_args(self):
        """Create mock AutoCoderArgs for testing"""
        return AutoCoderArgs(
            source_dir=".",
            context_prune=True,
            context_prune_strategy="extract",
            conversation_prune_safe_zone_tokens=30,  # è¿™ä¸ªä¸å¯¹context_prunner ç”Ÿæ•ˆ
            context_prune_sliding_window_size=10,
            context_prune_sliding_window_overlap=2,
            query="å¦‚ä½•å®ç°åŠ æ³•å’Œå‡æ³•è¿ç®—ï¼Ÿ"
        )

    @pytest.fixture
    def real_llm(self):
        """åˆ›å»ºçœŸå®çš„LLMå¯¹è±¡"""
        llm = get_llm("v3_chat", product_mode="lite")
        return llm

    @pytest.fixture
    def pruner(self, mock_args, real_llm):
        """Create PruneContext instance for testing"""
        # å¯¹ context_prunner ç”Ÿæ•ˆçš„æ˜¯ max_tokensè¿™é‡Œ
        return PruneContext(max_tokens=60, args=mock_args, llm=real_llm)

    @pytest.fixture
    def verbose_pruner(self, mock_args, real_llm):
        """Create PruneContext instance with verbose=True for testing"""
        return PruneContext(max_tokens=60, args=mock_args, llm=real_llm, verbose=True)

    @pytest.fixture
    def sample_file_sources(self, temp_test_dir):
        """Sample file sources for testing
        Creates a simulated project structure in the temporary directory
        """
        # åˆ›å»ºé¡¹ç›®ç»“æ„
        src_dir = os.path.join(temp_test_dir, "src")
        utils_dir = os.path.join(src_dir, "utils")
        os.makedirs(utils_dir, exist_ok=True)

        # åˆ›å»º __init__.py æ–‡ä»¶ä½¿å…¶æˆä¸ºæœ‰æ•ˆçš„ Python åŒ…
        with open(os.path.join(src_dir, "__init__.py"), "w") as f:
            f.write("# src package")
        with open(os.path.join(utils_dir, "__init__.py"), "w") as f:
            f.write("# utils package")

        # åˆ›å»ºæ•°å­¦å·¥å…·æ¨¡å—
        math_utils_content = '''def add(a, b):
    """åŠ æ³•å‡½æ•°"""
    return a + b

def subtract(a, b):
    """å‡æ³•å‡½æ•°"""
    return a - b

def multiply(a, b):
    """ä¹˜æ³•å‡½æ•°"""
    return a * b

def divide(a, b):
    """é™¤æ³•å‡½æ•°"""
    if b == 0:
        raise ValueError("Cannot divide by zero")
    return a / b
'''
        math_utils_path = os.path.join(utils_dir, "math_utils.py")
        with open(math_utils_path, "w") as f:
            f.write(math_utils_content)

        # åˆ›å»ºå­—ç¬¦ä¸²å·¥å…·æ¨¡å—
        string_utils_content = '''def format_string(s):
    """æ ¼å¼åŒ–å­—ç¬¦ä¸²"""
    return s.strip().lower()

def reverse_string(s):
    """åè½¬å­—ç¬¦ä¸²"""
    return s[::-1]

def count_characters(s):
    """è®¡ç®—å­—ç¬¦æ•°"""
    return len(s)
'''
        string_utils_path = os.path.join(utils_dir, "string_utils.py")
        with open(string_utils_path, "w") as f:
            f.write(string_utils_content)

        # åˆ›å»ºä¸»ç¨‹åºæ–‡ä»¶
        main_content = '''from utils.math_utils import add, subtract
from utils.string_utils import format_string

def main():
    print("è®¡ç®—ç»“æœ:", add(5, 3))
    print("æ ¼å¼åŒ–ç»“æœ:", format_string("  Hello World  "))

if __name__ == "__main__":
    main()
'''
        main_path = os.path.join(src_dir, "main.py")
        with open(main_path, "w") as f:
            f.write(main_content)

        # åˆ›å»º README æ–‡ä»¶
        readme_content = '''# æµ‹è¯•é¡¹ç›®

è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•çš„æ¨¡æ‹Ÿé¡¹ç›®ç»“æ„ã€‚

## åŠŸèƒ½

- æ•°å­¦è¿ç®—
- å­—ç¬¦ä¸²å¤„ç†
'''
        readme_path = os.path.join(temp_test_dir, "README.md")
        with open(readme_path, "w") as f:
            f.write(readme_content)

        # åˆå§‹åŒ–è¯¥é¡¹ç›®
        # ä¿å­˜å½“å‰å·¥ä½œç›®å½•
        original_cwd = os.getcwd()
        try:
            os.chdir(temp_test_dir)
            init_project_if_required(target_dir=temp_test_dir)
        finally:
            # ç«‹å³æ¢å¤å·¥ä½œç›®å½•ï¼Œé¿å…å½±å“åç»­æµ‹è¯•
            os.chdir(original_cwd)

        # è¿”å›ä¸åŸæ¥ç›¸åŒçš„ SourceCode å¯¹è±¡åˆ—è¡¨ï¼Œä½†ä½¿ç”¨ç›¸å¯¹è·¯å¾„ä½œä¸º module_name
        v = [
            SourceCode(
                module_name="src/utils/math_utils.py",
                source_code=math_utils_content,
                tokens=count_string_tokens(math_utils_content)
            ),
            SourceCode(
                module_name="src/utils/string_utils.py",
                source_code=string_utils_content,
                tokens=count_string_tokens(string_utils_content)
            ),
            SourceCode(
                module_name="src/main.py",
                source_code=main_content,
                tokens=count_string_tokens(main_content)
            )
        ]
                      
        return v

    @pytest.fixture
    def sample_conversations(self):
        """Sample conversations for testing"""
        return [
            {"role": "user", "content": "å¦‚ä½•å®ç°åŠ æ³•å’Œå‡æ³•è¿ç®—ï¼Ÿ"},
            {"role": "assistant", "content": "æˆ‘æ¥å¸®ä½ å®ç°åŠ æ³•å’Œå‡æ³•è¿ç®—ã€‚"}
        ]

    def test_extract_strategy_basic(self, pruner, sample_file_sources, sample_conversations):
        """æµ‹è¯•extractç­–ç•¥çš„åŸºæœ¬åŠŸèƒ½"""
        
        # è®¡ç®—è¾“å…¥çš„æ€»tokenæ•°
        original_total_tokens = sum(source.tokens for source in sample_file_sources)
        print(f"åŸå§‹æ€»tokenæ•°: {original_total_tokens}")

        result = pruner.handle_overflow(
            file_sources=sample_file_sources,
            conversations=sample_conversations,
            strategy="extract"
        )

        # éªŒè¯ç»“æœåŸºæœ¬ç»“æ„
        assert isinstance(result, list), "åº”è¯¥è¿”å›æ–‡ä»¶åˆ—è¡¨"
        print(f"è¿”å›æ–‡ä»¶æ•°é‡: {len(result)}")

        # éªŒè¯è¿”å›çš„æ˜¯SourceCodeå¯¹è±¡
        for item in result:
            assert isinstance(item, SourceCode), "è¿”å›çš„åº”è¯¥æ˜¯SourceCodeå¯¹è±¡"
            assert hasattr(item, 'module_name'), "SourceCodeåº”è¯¥æœ‰module_nameå±æ€§"
            assert hasattr(item, 'source_code'), "SourceCodeåº”è¯¥æœ‰source_codeå±æ€§"

        # å¦‚æœæœ‰ç»“æœï¼ŒéªŒè¯tokenå‹ç¼©æ•ˆæœ
        if len(result) > 0:
            # è®¡ç®—è¾“å‡ºçš„æ€»tokenæ•°
            result_total_tokens = sum(item.tokens for item in result)
            print(f"å¤„ç†åæ€»tokenæ•°: {result_total_tokens}")
            
            # éªŒè¯tokenæ•°ç¡®å®å‡å°‘äº†
            assert result_total_tokens < original_total_tokens, f"Tokenæ•°åº”è¯¥å‡å°‘ï¼ŒåŸå§‹: {original_total_tokens}, å¤„ç†å: {result_total_tokens}"
            
            # è®¡ç®—å‹ç¼©ç‡
            compression_rate = (original_total_tokens - result_total_tokens) / original_total_tokens * 100
            print(f"Tokenå‹ç¼©ç‡: {compression_rate:.1f}%")
            assert compression_rate > 0, "åº”è¯¥æœ‰æœ‰æ•ˆçš„å‹ç¼©ç‡"
            
            # éªŒè¯ä¸æŸ¥è¯¢ç›¸å…³çš„å‡½æ•°æ˜¯å¦åœ¨ç»“æœä¸­ï¼ˆç”¨æˆ·æŸ¥è¯¢ï¼š"å¦‚ä½•å®ç°åŠ æ³•å’Œå‡æ³•è¿ç®—ï¼Ÿ"ï¼‰
            combined_content = "\n".join(item.source_code for item in result)
            print(f"åˆå¹¶åçš„å†…å®¹é•¿åº¦: {len(combined_content)} å­—ç¬¦")
            
            # æ£€æŸ¥åŠ æ³•å’Œå‡æ³•ç›¸å…³çš„å‡½æ•°æ˜¯å¦å­˜åœ¨
            has_add_function = "def add(" in combined_content or "add(" in combined_content
            has_subtract_function = "def subtract(" in combined_content or "subtract(" in combined_content
            
            print(f"åŒ…å«addå‡½æ•°: {has_add_function}")
            print(f"åŒ…å«subtractå‡½æ•°: {has_subtract_function}")
            
            # è‡³å°‘åº”è¯¥åŒ…å«å…¶ä¸­ä¸€ä¸ªç›¸å…³å‡½æ•°
            assert has_add_function or has_subtract_function, "è£å‰ªåçš„ç»“æœåº”è¯¥åŒ…å«ä¸æŸ¥è¯¢ç›¸å…³çš„åŠ æ³•æˆ–å‡æ³•å‡½æ•°"
            
            # éªŒè¯math_utils.pyæ˜¯å¦åœ¨ç»“æœä¸­ï¼ˆå› ä¸ºå®ƒåŒ…å«ç›¸å…³å‡½æ•°ï¼‰
            math_utils_files = [item for item in result if "math_utils.py" in item.module_name]
            if math_utils_files:
                math_utils_content = math_utils_files[0].source_code
                print(f"math_utils.pyå¤„ç†åå†…å®¹:\n{math_utils_content}")
                
                # éªŒè¯åŒ…å«Snippetsæ ‡è®°ï¼ˆè¯´æ˜ç»è¿‡äº†ä»£ç ç‰‡æ®µæŠ½å–ï¼‰
                assert "Snippets:" in math_utils_content, "math_utils.pyåº”è¯¥åŒ…å«ä»£ç ç‰‡æ®µæŠ½å–æ ‡è®°"
                
        else:
            print("âš ï¸ Extractç­–ç•¥è¿”å›ç©ºç»“æœï¼ˆè¿™å¯èƒ½å‘ç”Ÿåœ¨LLMè¶…æ—¶æˆ–å…¶ä»–å¼‚å¸¸æƒ…å†µä¸‹ï¼‰")

    def test_sliding_window_split(self, pruner):
        """æµ‹è¯•æ»‘åŠ¨çª—å£åˆ†å‰²åŠŸèƒ½"""
        # åˆ›å»ºä¸€ä¸ªè¾ƒé•¿çš„å†…å®¹ç”¨äºæµ‹è¯•ï¼ˆ20è¡Œï¼‰
        content = "\n".join([f"line {i}: some content here" for i in range(1, 21)])
        content_lines = content.split('\n')
        total_lines = len(content_lines)
        
        print(f"æµ‹è¯•å†…å®¹æ€»è¡Œæ•°: {total_lines}")

        # æµ‹è¯•ä¸åŒçš„æ»‘åŠ¨çª—å£é…ç½®
        test_cases = [
            {
                "window_size": 5,
                "overlap": 2,
                "expected_chunks": 7,  # åŸºäºå®é™…è¿è¡Œç»“æœ
                "description": "æ ‡å‡†æ»‘åŠ¨çª—å£é…ç½®"
            },
            {
                "window_size": 3, 
                "overlap": 1,
                "expected_chunks": 10,  # åŸºäºå®é™…è¿è¡Œç»“æœ
                "description": "å°çª—å£é«˜é‡å é…ç½®"
            },
            {
                "window_size": 10,
                "overlap": 3, 
                "expected_chunks": 3,  # åŸºäºå®é™…è¿è¡Œç»“æœ
                "description": "å¤§çª—å£ä¸­ç­‰é‡å é…ç½®"
            },
            {
                "window_size": 7,
                "overlap": 0,
                "expected_chunks": 3,  # åŸºäºå®é™…è¿è¡Œç»“æœ
                "description": "æ— é‡å é…ç½®"
            }
        ]

        for case in test_cases:
            window_size = case["window_size"]
            overlap = case["overlap"]
            expected_chunks = case["expected_chunks"]
            description = case["description"]
            
            print(f"\nğŸ” æµ‹è¯• {description}: çª—å£={window_size}, é‡å ={overlap}")
            
            chunks = pruner._split_content_with_sliding_window(
                content=content,
                window_size=window_size,
                overlap=overlap
            )

            # éªŒè¯åŸºæœ¬ç»“æ„
            assert isinstance(chunks, list), f"åº”è¯¥è¿”å›chunkåˆ—è¡¨ ({description})"
            assert len(chunks) == expected_chunks, f"åº”è¯¥æœ‰ {expected_chunks} ä¸ªchunksï¼Œå®é™…: {len(chunks)} ({description})"

            # éªŒè¯chunkç»“æ„å’Œå†…å®¹
            for i, chunk in enumerate(chunks):
                assert isinstance(chunk, tuple), f"Chunk {i+1} åº”è¯¥æ˜¯å…ƒç»„ ({description})"
                assert len(chunk) == 3, f"Chunk {i+1} åº”è¯¥åŒ…å«3ä¸ªå…ƒç´  ({description})"
                
                start_line, end_line, chunk_content = chunk
                assert isinstance(start_line, int), f"Chunk {i+1} èµ·å§‹è¡Œå·åº”è¯¥æ˜¯æ•´æ•° ({description})"
                assert isinstance(end_line, int), f"Chunk {i+1} ç»“æŸè¡Œå·åº”è¯¥æ˜¯æ•´æ•° ({description})"
                assert isinstance(chunk_content, str), f"Chunk {i+1} å†…å®¹åº”è¯¥æ˜¯å­—ç¬¦ä¸² ({description})"
                assert start_line <= end_line, f"Chunk {i+1} èµ·å§‹è¡Œå·åº”è¯¥ <= ç»“æŸè¡Œå· ({description})"
                
                # éªŒè¯è¡Œå·èŒƒå›´åˆç†
                assert 1 <= start_line <= total_lines, f"Chunk {i+1} èµ·å§‹è¡Œå·åº”è¯¥åœ¨1-{total_lines}èŒƒå›´å†… ({description})"
                assert 1 <= end_line <= total_lines, f"Chunk {i+1} ç»“æŸè¡Œå·åº”è¯¥åœ¨1-{total_lines}èŒƒå›´å†… ({description})"
                
                # éªŒè¯å†…å®¹è¡Œæ•°ä¸è¡Œå·èŒƒå›´ä¸€è‡´
                chunk_lines = chunk_content.split('\n')
                expected_line_count = end_line - start_line + 1
                # æ³¨æ„ï¼šç”±äºchunk_contentä¸­å¯èƒ½åŒ…å«è¡Œå·å‰ç¼€ï¼Œå®é™…è¡Œæ•°å¯èƒ½ä¸åŒ
                # æˆ‘ä»¬ä¸»è¦éªŒè¯å†…å®¹ä¸ä¸ºç©ºä¸”åˆç†
                assert len(chunk_content) > 0, f"Chunk {i+1} å†…å®¹ä¸åº”ä¸ºç©º ({description})"
                
                print(f"   Chunk {i+1}: è¡Œ {start_line}-{end_line} ({len(chunk_lines)} è¡Œ)")

            # éªŒè¯é‡å é€»è¾‘
            if overlap > 0 and len(chunks) > 1:
                for i in range(len(chunks) - 1):
                    current_start, current_end, _ = chunks[i]
                    next_start, next_end, _ = chunks[i + 1]
                    
                    # éªŒè¯æœ‰é‡å 
                    if i < len(chunks) - 2:  # ä¸æ˜¯æœ€åä¸€ä¸ªchunkå¯¹
                        overlap_lines = current_end - next_start + 1
                        assert overlap_lines >= overlap, f"Chunk {i+1} å’Œ {i+2} é‡å è¡Œæ•°åº”è¯¥ >= {overlap}ï¼Œå®é™…: {overlap_lines} ({description})"
            
            # éªŒè¯è¦†ç›–å®Œæ•´æ€§ï¼ˆæ‰€æœ‰è¡Œéƒ½è¢«è¦†ç›–ï¼‰
            covered_lines = set()
            for start_line, end_line, _ in chunks:
                for line_num in range(start_line, end_line + 1):
                    covered_lines.add(line_num)
            
            expected_lines = set(range(1, total_lines + 1))
            assert covered_lines == expected_lines, f"åº”è¯¥è¦†ç›–æ‰€æœ‰è¡Œ1-{total_lines} ({description})"
            
            print(f"   âœ… éªŒè¯é€šè¿‡: {len(chunks)} ä¸ªchunksï¼Œè¦†ç›–æ‰€æœ‰ {total_lines} è¡Œ")

        # è¿½åŠ åŸºäºmath_utils_contentçš„çœŸå®ä»£ç æµ‹è¯•
        print(f"\nğŸ§® æµ‹è¯•çœŸå®ä»£ç å†…å®¹ - math_utils.py")
        math_utils_content = '''def add(a, b):
    """åŠ æ³•å‡½æ•°"""
    return a + b

def subtract(a, b):
    """å‡æ³•å‡½æ•°"""
    return a - b

def multiply(a, b):
    """ä¹˜æ³•å‡½æ•°"""
    return a * b

def divide(a, b):
    """é™¤æ³•å‡½æ•°"""
    if b == 0:
        raise ValueError("Cannot divide by zero")
    return a / b
'''
        
        math_content_lines = math_utils_content.split('\n')
        math_total_lines = len([line for line in math_content_lines if line.strip()])  # åªè®¡ç®—éç©ºè¡Œ
        print(f"math_utils.py æ€»è¡Œæ•°: {len(math_content_lines)} (éç©ºè¡Œ: {math_total_lines})")
        
        # æµ‹è¯•é€‚åˆä»£ç çš„çª—å£é…ç½®
        math_test_cases = [
            {
                "window_size": 4,
                "overlap": 1,
                "description": "å°çª—å£é…ç½®é€‚åˆå‡½æ•°åˆ†å‰²"
            },
            {
                "window_size": 6,
                "overlap": 2,
                "description": "ä¸­ç­‰çª—å£é…ç½®åŒ…å«å®Œæ•´å‡½æ•°"
            }
        ]
        
        for case in math_test_cases:
            window_size = case["window_size"]
            overlap = case["overlap"]
            description = case["description"]
            
            print(f"\nğŸ” æµ‹è¯• {description}: çª—å£={window_size}, é‡å ={overlap}")
            
            chunks = pruner._split_content_with_sliding_window(
                content=math_utils_content,
                window_size=window_size,
                overlap=overlap
            )
            
            print(f"   ç”Ÿæˆ {len(chunks)} ä¸ªchunks:")
            
            # éªŒè¯åŸºæœ¬ç»“æ„
            assert isinstance(chunks, list), f"åº”è¯¥è¿”å›chunkåˆ—è¡¨ ({description})"
            assert len(chunks) > 0, f"åº”è¯¥è‡³å°‘æœ‰ä¸€ä¸ªchunk ({description})"
            
            # åˆ†ææ¯ä¸ªchunkçš„å†…å®¹
            function_keywords = ["def add(", "def subtract(", "def multiply(", "def divide("]
            
            for i, chunk in enumerate(chunks):
                start_line, end_line, chunk_content = chunk
                print(f"   Chunk {i+1}: è¡Œ {start_line}-{end_line}")
                
                # æ£€æŸ¥è¿™ä¸ªchunkåŒ…å«å“ªäº›å‡½æ•°å®šä¹‰
                found_functions = []
                for keyword in function_keywords:
                    if keyword in chunk_content:
                        func_name = keyword[4:-1]  # æå–å‡½æ•°å (å»æ‰ "def " å’Œ "(")
                        found_functions.append(func_name)
                
                if found_functions:
                    print(f"      åŒ…å«å‡½æ•°: {', '.join(found_functions)}")
                else:
                    print(f"      åŒ…å«: å‡½æ•°ä½“æˆ–æ³¨é‡Šéƒ¨åˆ†")
                
                # éªŒè¯åŸºæœ¬ç»“æ„
                assert isinstance(chunk, tuple), f"Chunk {i+1} åº”è¯¥æ˜¯å…ƒç»„ ({description})"
                assert len(chunk) == 3, f"Chunk {i+1} åº”è¯¥åŒ…å«3ä¸ªå…ƒç´  ({description})"
                assert isinstance(start_line, int), f"Chunk {i+1} èµ·å§‹è¡Œå·åº”è¯¥æ˜¯æ•´æ•° ({description})"
                assert isinstance(end_line, int), f"Chunk {i+1} ç»“æŸè¡Œå·åº”è¯¥æ˜¯æ•´æ•° ({description})"
                assert isinstance(chunk_content, str), f"Chunk {i+1} å†…å®¹åº”è¯¥æ˜¯å­—ç¬¦ä¸² ({description})"
                assert len(chunk_content.strip()) > 0, f"Chunk {i+1} å†…å®¹ä¸åº”ä¸ºç©º ({description})"
            
            # éªŒè¯æ‰€æœ‰å‡½æ•°å®šä¹‰éƒ½è¢«è¦†ç›–
            all_chunk_content = "\n".join(chunk[2] for chunk in chunks)
            for keyword in function_keywords:
                assert keyword in all_chunk_content, f"åº”è¯¥è¦†ç›–å‡½æ•°å®šä¹‰: {keyword} ({description})"
                
            print(f"   âœ… éªŒè¯é€šè¿‡: æ‰€æœ‰å‡½æ•°å®šä¹‰éƒ½è¢«è¦†ç›–")

    def test_merge_overlapping_snippets(self, pruner):
        """æµ‹è¯•é‡å ç‰‡æ®µåˆå¹¶åŠŸèƒ½"""
        # æµ‹è¯•é‡å ç‰‡æ®µ
        snippets = [
            {"start_line": 1, "end_line": 5},
            {"start_line": 4, "end_line": 8},
            {"start_line": 10, "end_line": 15}
        ]

        merged = pruner._merge_overlapping_snippets(snippets)

        # éªŒè¯ç»“æœ
        assert isinstance(merged, list), "åº”è¯¥è¿”å›ç‰‡æ®µåˆ—è¡¨"
        assert len(merged) == 2, "åº”è¯¥åˆå¹¶ä¸º2ä¸ªç‰‡æ®µ"

        # éªŒè¯åˆå¹¶ç»“æœ
        assert merged[0]["start_line"] == 1, "ç¬¬ä¸€ä¸ªç‰‡æ®µèµ·å§‹è¡Œåº”è¯¥æ˜¯1"
        assert merged[0]["end_line"] == 8, "ç¬¬ä¸€ä¸ªç‰‡æ®µç»“æŸè¡Œåº”è¯¥æ˜¯8"
        assert merged[1]["start_line"] == 10, "ç¬¬äºŒä¸ªç‰‡æ®µèµ·å§‹è¡Œåº”è¯¥æ˜¯10"
        assert merged[1]["end_line"] == 15, "ç¬¬äºŒä¸ªç‰‡æ®µç»“æŸè¡Œåº”è¯¥æ˜¯15"

    def test_build_snippet_content(self, pruner):
        """æµ‹è¯•æ„å»ºç‰‡æ®µå†…å®¹åŠŸèƒ½"""
        full_content = """def add(a, b):
    return a + b

def subtract(a, b):
    return a - b

def multiply(a, b):
    return a * b"""

        snippets = [
            {"start_line": 1, "end_line": 2},
            {"start_line": 4, "end_line": 5}
        ]

        result = pruner._build_snippet_content(
            "test.py", full_content, snippets)

        # éªŒè¯ç»“æœ
        assert isinstance(result, str), "åº”è¯¥è¿”å›å­—ç¬¦ä¸²"
        assert "Snippets:" in result, "åº”è¯¥åŒ…å«Snippetsæ ‡é¢˜"
        assert "def add(a, b):" in result, "åº”è¯¥åŒ…å«addå‡½æ•°"
        assert "def subtract(a, b):" in result, "åº”è¯¥åŒ…å«subtractå‡½æ•°"

    def test_invalid_strategy(self, pruner, sample_file_sources, sample_conversations):
        """æµ‹è¯•æ— æ•ˆç­–ç•¥å¤„ç†"""
        with pytest.raises(ValueError) as exc_info:
            pruner.handle_overflow(
                file_sources=sample_file_sources,
                conversations=sample_conversations,
                strategy="invalid_strategy"
            )

        assert "æ— æ•ˆç­–ç•¥" in str(exc_info.value), "åº”è¯¥æŠ›å‡ºæ— æ•ˆç­–ç•¥é”™è¯¯"

    def test_verbose_functionality(self, verbose_pruner, sample_file_sources, sample_conversations, capsys):
        """æµ‹è¯•verboseå‚æ•°çš„åŠŸèƒ½"""
        # ä½¿ç”¨verbose=Trueçš„prunerè¿›è¡Œæµ‹è¯•
        result = verbose_pruner.handle_overflow(
            file_sources=sample_file_sources,
            conversations=sample_conversations,
            strategy="extract"
        )

        # æ•è·è¾“å‡º
        captured = capsys.readouterr()
        
        # éªŒè¯verboseè¾“å‡ºåŒ…å«é¢„æœŸçš„ä¿¡æ¯
        assert "ğŸš€ å¼€å§‹ä»£ç ç‰‡æ®µæŠ½å–å¤„ç†" in captured.out, "åº”è¯¥åŒ…å«å¼€å§‹å¤„ç†çš„ä¿¡æ¯"
        assert "ğŸ“‹ å¤„ç†ç­–ç•¥" in captured.out, "åº”è¯¥åŒ…å«å¤„ç†ç­–ç•¥ä¿¡æ¯"
        assert "ğŸ¯ ä»£ç ç‰‡æ®µæŠ½å–å¤„ç†å®Œæˆ" in captured.out, "åº”è¯¥åŒ…å«å¤„ç†å®Œæˆçš„ä¿¡æ¯"
        assert "ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡" in captured.out, "åº”è¯¥åŒ…å«ç»“æœç»Ÿè®¡ä¿¡æ¯"
        
        # éªŒè¯ç»“æœä»ç„¶æ­£ç¡®
        assert isinstance(result, list), "åº”è¯¥è¿”å›æ–‡ä»¶åˆ—è¡¨"
        assert len(result) >= 0, "åº”è¯¥è¿”å›æœ‰æ•ˆçš„ç»“æœåˆ—è¡¨"

    def test_non_verbose_functionality(self, pruner, sample_file_sources, sample_conversations, capsys):
        """æµ‹è¯•verbose=Falseæ—¶ä¸è¾“å‡ºè¯¦ç»†ä¿¡æ¯"""
        # ä½¿ç”¨verbose=Falseçš„prunerè¿›è¡Œæµ‹è¯•
        result = pruner.handle_overflow(
            file_sources=sample_file_sources,
            conversations=sample_conversations,
            strategy="extract"
        )

        # æ•è·è¾“å‡º
        captured = capsys.readouterr()
        
        # éªŒè¯ä¸åŒ…å«verboseç‰¹æœ‰çš„è¾“å‡º
        assert "ğŸš€ å¼€å§‹ä»£ç ç‰‡æ®µæŠ½å–å¤„ç†" not in captured.out, "éverboseæ¨¡å¼ä¸åº”è¯¥åŒ…å«è¯¦ç»†å¤„ç†ä¿¡æ¯"
        assert "ğŸ“‹ å¤„ç†ç­–ç•¥" not in captured.out, "éverboseæ¨¡å¼ä¸åº”è¯¥åŒ…å«å¤„ç†ç­–ç•¥ä¿¡æ¯"
        assert "ğŸ¯ ä»£ç ç‰‡æ®µæŠ½å–å¤„ç†å®Œæˆ" not in captured.out, "éverboseæ¨¡å¼ä¸åº”è¯¥åŒ…å«å¤„ç†å®Œæˆçš„è¯¦ç»†ä¿¡æ¯"
        
        # éªŒè¯ç»“æœä»ç„¶æ­£ç¡®
        assert isinstance(result, list), "åº”è¯¥è¿”å›æ–‡ä»¶åˆ—è¡¨"
        assert len(result) >= 0, "åº”è¯¥è¿”å›æœ‰æ•ˆçš„ç»“æœåˆ—è¡¨"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
