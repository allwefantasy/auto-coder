import locale
from byzerllm.utils import format_str_jinja2

MESSAGES = {
    "en": {
        "file_scored_message": "File scored: {{file_path}} - Score: {{score}}",
        "invalid_file_pattern": "Invalid file pattern: {{file_pattern}}. e.g. regex://.*/package-lock\\.json",
        "config_validation_error": "Config validation error: {{error}}",
        "invalid_boolean_value": "Value '{{value}}' is not a valid boolean(true/false)",
        "invalid_integer_value": "Value '{{value}}' is not a valid integer",
        "invalid_float_value": "Value '{{value}}' is not a valid float",
        "invalid_type_value": "Value '{{value}}' is not a valid type (expected: {{types}})",
        "value_out_of_range": "Value {{value}} is out of allowed range({{min}}~{{max}})",
        "invalid_choice": "Value '{{value}}' is not in allowed options({{allowed}})",
        "unknown_config_key": "Unknown config key '{{key}}'",
        "model_not_found": "Model '{{model}}' is not configured in models.yml",
        "required_without_default": "Config key '{{key}}' requires explicit value",
        "auto_command_action_break": "Command {{command}} execution failed (got {{action}} result), no result can be obtained, please try again",
        "auto_command_break": "Auto command execution failed to execute command: {{command}}",
        "auto_command_executing": "\n\n============= Executing command: {{command}} =============\n\n",
        "model_provider_select_title": "Select Model Provider",
        "auto_config_analyzing": "Analyzing configuration...",
        "config_delete_success": "Successfully deleted configuration: {{key}}",
        "config_not_found": "Configuration not found: {{key}}",
        "config_invalid_format": "Invalid configuration format. Expected 'key:value'",
        "config_value_empty": "Configuration value cannot be empty",
        "config_set_success": "Successfully set configuration: {{key}} = {{value}}",
        "model_provider_select_text": "Please select your model provider:",
        "model_provider_volcano": "Volcano Engine",
        "model_provider_siliconflow": "SiliconFlow AI",
        "model_provider_deepseek": "DeepSeek Official",        
        "model_provider_api_key_title": "API Key",
        "model_provider_volcano_api_key_text": "Please enter your Volcano Engine API key:",
        "model_provider_volcano_r1_text": "Please enter your Volcano Engine R1 endpoint (format: ep-20250204215011-vzbsg):",
        "model_provider_volcano_v3_text": "Please enter your Volcano Engine V3 endpoint (format: ep-20250204215011-vzbsg):",
        "model_provider_siliconflow_api_key_text": "Please enter your SiliconFlow AI API key:",
        "model_provider_deepseek_api_key_text": "Please enter your DeepSeek API key:",
        "model_provider_selected": "Provider configuration completed successfully! You can use /models command to view, add and modify all models later.",
        "model_provider_success_title": "Success",
        "index_file_filtered": "File {{file_path}} is filtered by model {{model_name}} restrictions",
        "models_no_active": "No active models found",
        "models_speed_test_results": "Model Speed Test Results",
        "models_testing": "Testing model: {{name}}...",
        "models_testing_start": "Starting speed test for all active models...",
        "models_testing_progress": "Testing progress: {{ completed }}/{{ total }} models",
        "generation_cancelled": "[Interrupted] Generation cancelled",
        "model_not_found": "Model {{model_name}} not found",
        "generating_shell_script": "Generating Shell Script",
        "new_session_started": "New session started. Previous chat history has been archived.",
        "memory_save_success": "âœ… Saved to your memory",
        "file_decode_error": "Failed to decode file: {{file_path}}. Tried encodings: {{encodings}}",
        "file_write_error": "Failed to write file: {{file_path}}. Error: {{error}}",
        "yaml_load_error": "Error loading yaml file {{yaml_file}}: {{error}}",
        "git_command_error": "Git command execution error: {{error}}",
        "get_commit_diff_error": "Error getting commit diff: {{error}}",
        "no_latest_commit": "Unable to get latest commit information",
        "code_review_error": "Code review process error: {{error}}",
        "index_file_too_large": "âš ï¸ File {{ file_path }} is too large ({{ file_size }} > {{ max_length }}), splitting into chunks...",
        "index_update_success": "âœ… {{ model_name }} Successfully updated index for {{ file_path }} (md5: {{ md5 }}) in {{ duration }}s, input_tokens: {{ input_tokens }}, output_tokens: {{ output_tokens }}, input_cost: {{ input_cost }}, output_cost: {{ output_cost }}",
        "index_build_error": "âŒ {{ model_name }} Error building index for {{ file_path }}: {{ error }}",
        "index_build_summary": "ğŸ“Š Total Files: {{ total_files }}, Need to Build Index: {{ num_files }}",
        "building_index_progress": "â³ Building Index: {{ counter }}/{{ num_files }}...",
        "index_source_dir_mismatch": "âš ï¸ Source directory mismatch (file_path: {{ file_path }}, source_dir: {{ source_dir }})",
        "index_related_files_fail": "âš ï¸ Failed to find related files for chunk {{ chunk_count }}",
        "index_threads_completed": "âœ… Completed {{ completed_threads }}/{{ total_threads }} threads",
        "index_related_files_fail": "âš ï¸ Failed to find related files for chunk {{ chunk_count }}",
        "index_file_removed": "ğŸ—‘ï¸ Removed non-existent file index: {{ file_path }}",
        "index_file_saved": "ğŸ’¾ Saved index file, updated {{ updated_files }} files, removed {{ removed_files }} files, input_tokens: {{ input_tokens }}, output_tokens: {{ output_tokens }}, input_cost: {{ input_cost }}, output_cost: {{ output_cost }}",
        "human_as_model_instructions": (
            "You are now in Human as Model mode. The content has been copied to your clipboard.\n"
            "The system is waiting for your input. When finished, enter 'EOF' on a new line to submit.\n"
            "Use '/break' to exit this mode. If you have issues with copy-paste, use '/clear' to clean and paste again."
        ),
        "clipboard_not_supported": (
            "pyperclip not installed or clipboard is not supported, instruction will not be copied to clipboard."
        ),
        "human_as_model_instructions_no_clipboard": (
            "You are now in Human as Model mode. [bold red]The content could not be copied to your clipboard.[/bold red]\n"
            "but you can copy prompt from output.txt file.\n"
            "The system is waiting for your input. When finished, enter 'EOF' on a new line to submit.\n"
            "Use '/break' to exit this mode. If you have issues with copy-paste, use '/clear' to clean and paste again."
        ),
        "phase1_processing_sources": "Phase 1: Processing REST/RAG/Search sources...",
        "phase2_building_index": "Phase 2: Building index for all files...",
        "phase6_file_selection": "Phase 6: Processing file selection and limits...",
        "phase7_preparing_output": "Phase 7: Preparing final output...",
        "chat_human_as_model_instructions": (
            "Chat is now in Human as Model mode.\n"
            "The question has been copied to your clipboard.\n"
            "Please use Web version model to get the answer.\n"
            "Or use /conf human_as_model:false to close this mode and get the answer in terminal directly."
            "Paste the answer to the input box below, use '/break' to exit, '/clear' to clear the screen, '/eof' to submit."
        ),
        "code_generation_start": "Auto generate the code...",
        "code_generation_complete": "{{ model_names}} Code generation completed in {{ duration }} seconds (sampling_count: {{ sampling_count }}), input_tokens_count: {{ input_tokens }}, generated_tokens_count: {{ output_tokens }}, input_cost: {{ input_cost }}, output_cost: {{ output_cost }}, speed: {{ speed }} tokens/s",
        "code_merge_start": "Auto merge the code...",
        "code_execution_warning": "Content(send to model) is {{ content_length }} tokens (you may collect too much files), which is larger than the maximum input length {{ max_length }}",
        "quick_filter_start": "{{ model_name }} Starting filter context(quick_filter)...",
        "normal_filter_start": "{{ model_name }} Starting filter context(normal_filter)...",
        "pylint_check_failed": "âš ï¸ Pylint check failed: {{ error_message }}",
        "pylint_error": "âŒ Error running pylint: {{ error_message }}",
        "unmerged_blocks_warning": "âš ï¸ Found {{ num_blocks }} unmerged blocks, the changes will not be applied. Please review them manually then try again.",
        "pylint_file_check_failed": "âš ï¸ Pylint check failed for {{ file_path }}. Changes not applied. Error: {{ error_message }}",
        "merge_success": "âœ… Merged changes in {{ num_files }} files {{ num_changes }}/{{ total_blocks }} blocks.",
        "no_changes_made": "âš ï¸ No changes were made to any files.",
        "files_merged": "âœ… Merged {{ total }} files into the project.",
        "merge_failed": "âŒ Merge file {{ path }} failed: {{ error }}",
        "files_merged_total": "âœ… Merged {{ total }} files into the project.",
        "ranking_skip": "Only 1 candidate, skip ranking",
        "ranking_start": "Start ranking {{ count }} candidates using model {{ model_name }}",
        "ranking_failed_request": "Ranking request failed: {{ error }}",
        "ranking_all_failed": "All ranking requests failed",
        "ranking_complete": "{{ model_names }} Ranking completed in {{ elapsed }}s, total voters: {{ total_tasks }}, best candidate index: {{ best_candidate }}, scores: {{ scores }}, input_tokens: {{ input_tokens }}, output_tokens: {{ output_tokens }}, input_cost: {{ input_cost }}, output_cost: {{ output_cost }}, speed: {{ speed }} tokens/s",
        "ranking_process_failed": "Ranking process failed: {{ error }}",
        "ranking_failed": "Ranking failed in {{ elapsed }}s, using original order",
        "begin_index_source_code": "ğŸš€ Begin to index source code in {{ source_dir }}",
        "stream_out_stats": "Model: {{ model_name }}, Total time: {{ elapsed_time }} seconds, First token time: {{ first_token_time }} seconds, Speed: {{ speed }} tokens/s, Input tokens: {{ input_tokens }}, Output tokens: {{ output_tokens }}, Input cost: {{ input_cost }}, Output cost: {{ output_cost }}",
        "quick_filter_stats": "{{ model_names }} Quick filter completed in {{ elapsed_time }} seconds, input tokens: {{ input_tokens }}, output tokens: {{ output_tokens }}, input cost: {{ input_cost }}, output cost: {{ output_cost }} speed: {{ speed }} tokens/s",
        "upsert_file": "âœ… Updated file: {{ file_path }}",
        "unmerged_blocks_title": "Unmerged Blocks",
        "merged_blocks_title": "Merged Changes",
        "quick_filter_title": "{{ model_name }} is analyzing how to filter context...",
        "quick_filter_failed": "âŒ Quick filter failed: {{ error }}. ",
        "unmerged_file_path": "File: {{file_path}}",
        "unmerged_search_block": "Search Block({{similarity}}):",
        "unmerged_replace_block": "Replace Block:",
        "unmerged_blocks_total": "Total unmerged blocks: {{num_blocks}}",
        "git_init_required": "âš ï¸ auto_merge only applies to git repositories.\n\nPlease try using git init in the source directory:\n\n```shell\ncd {{ source_dir }}\ngit init.\n```\n\nThen run auto - coder again.\nError: {{ error }}",
        "quick_filter_reason": "Auto get(quick_filter mode)",
        "quick_filter_too_long": "âš ï¸ index file is too large ({{ tokens_len }}/{{ max_tokens }}). The query will be split into {{ split_size }} chunks.",
        "quick_filter_tokens_len": "ğŸ“Š Current index size: {{ tokens_len }} tokens",
        "estimated_chat_input_tokens": "Estimated chat input tokens: {{ estimated_input_tokens }}",
        "estimated_input_tokens_in_generate": "Estimated input tokens in generate ({{ generate_mode }}): {{ estimated_input_tokens_in_generate }}",        
        "model_has_access_restrictions": "{{model_name}} has access restrictions, cannot use the current function",
        "auto_command_not_found": "Auto command not found: {{command}}. Please check your input and try again.",
        "auto_command_failed": "Auto command failed: {{error}}. Please check your input and try again.",
        "command_execution_result": "{{action}} execution result",
        "satisfied_prompt": "Requirements satisfied, no further action needed",
        "auto_command_analyzed": "Selected command",
        "invalid_enum_value": "Value '{{value}}' is not in allowed values ({{allowed}})",
        "no_changes_made": "âš ï¸ no changes made, the reason may be that the text block generated by the coding function has a problem, so it cannot be merged into the project",
        "conversation_pruning_start": "âš ï¸ Conversation pruning started, total tokens: {{total_tokens}}, safe zone: {{safe_zone}}",
        "invalid_file_number": "âš ï¸ Invalid file number {{file_number}}, total files: {{total_files}}",
        "all_merge_results_failed": "âš ï¸ All merge attempts failed, returning first candidate",
        "only_one_merge_result_success": "âœ… Only one merge result succeeded, returning that candidate",
        "conf_import_success": "Successfully imported configuration: {{path}}",
        "conf_export_success": "Successfully exported configuration: {{path}}",
        "conf_import_error": "Error importing configuration: {{error}}",
        "conf_export_error": "Error exporting configuration: {{error}}",
        "conf_import_invalid_format": "Invalid import configuration format, expected 'key:value'",
        "conf_export_invalid_format": "Invalid export configuration format, expected 'key:value'",
        "conf_import_file_not_found": "Import configuration file not found: {{file_path}}",
        "conf_export_file_not_found": "Export configuration file not found: {{file_path}}",
        "conf_import_file_empty": "Import configuration file is empty: {{file_path}}",
        "conf_export_file_empty": "Export configuration file is empty: {{file_path}}",
        "generated_shell_script": "Generated Shell Script",
        "confirm_execute_shell_script": "Do you want to execute this shell script?",
        "shell_script_not_executed": "Shell script was not executed",
        "conf_not_found": "Configuration file not found: {{path}}",
        "index_export_success": "Index exported successfully: {{path}}",
        "index_import_success": "Index imported successfully: {{path}}",
        "edits_title": "edits",
        "diff_blocks_title":"diff blocks",
        "index_exclude_files_error": "index filter exclude files fail: {{ error }}",
        "file_sliding_window_processing": "File {{ file_path }} is too large ({{ tokens }} tokens), processing with sliding window...",
        "file_snippet_processing": "Processing file {{ file_path }} with code snippet extraction...",
        "context_pruning_start": "âš ï¸ Context pruning started. Total tokens: {{ total_tokens }} (max allowed: {{ max_tokens }}). Applying strategy: {{ strategy }}.",
        "context_pruning_reason": "Context length exceeds maximum limit ({{ total_tokens }} > {{ max_tokens }}). Pruning is required to fit within the model's context window.",
        "rank_code_modification_title": "{{model_name}} ranking codes",
        "sorted_files_message": "Reordered files:\n{% for file in files %}- {{ file }}\n{% endfor %}",
        "estimated_input_tokens_in_ranking": "estimate input token {{ estimated_input_tokens }} when ranking",
        "file_snippet_procesed": "{{ file_path }} processed with tokens: {{ tokens }} => {{ snippet_tokens }}. Current total tokens: {{ total_tokens }}",
        "tool_ask_user": "Your Reply: ",
        "tool_ask_user_accept":"Your Response received",
        
    },
    "zh": {
        "file_sliding_window_processing": "æ–‡ä»¶ {{ file_path }} è¿‡å¤§ ({{ tokens }} tokens)ï¼Œæ­£åœ¨ä½¿ç”¨æ»‘åŠ¨çª—å£å¤„ç†...",
        "file_snippet_processing": "æ­£åœ¨å¯¹æ–‡ä»¶ {{ file_path }} è¿›è¡Œä»£ç ç‰‡æ®µæå–...",
        "context_pruning_start": "âš ï¸ å¼€å§‹ä¸Šä¸‹æ–‡å‰ªæã€‚æ€»tokenæ•°: {{ total_tokens }} (æœ€å¤§å…è®¸: {{ max_tokens }})ã€‚æ­£åœ¨åº”ç”¨ç­–ç•¥: {{ strategy }}ã€‚",
        "context_pruning_reason": "ä¸Šä¸‹æ–‡é•¿åº¦è¶…è¿‡æœ€å¤§é™åˆ¶ ({{ total_tokens }} > {{ max_tokens }})ã€‚éœ€è¦è¿›è¡Œå‰ªæä»¥é€‚é…æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£ã€‚",
        "file_scored_message": "æ–‡ä»¶è¯„åˆ†: {{file_path}} - åˆ†æ•°: {{score}}",
        "invalid_file_pattern": "æ— æ•ˆçš„æ–‡ä»¶æ¨¡å¼: {{file_pattern}}. ä¾‹å¦‚: regex://.*/package-lock\\.json",
        "conf_not_found": "æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶: {{path}}",
        "conf_import_success": "æˆåŠŸå¯¼å…¥é…ç½®: {{path}}",
        "conf_export_success": "æˆåŠŸå¯¼å‡ºé…ç½®: {{path}}",
        "conf_import_error": "å¯¼å…¥é…ç½®å‡ºé”™: {{error}}",
        "conf_export_error": "å¯¼å‡ºé…ç½®å‡ºé”™: {{error}}",
        "conf_import_invalid_format": "å¯¼å…¥é…ç½®æ ¼å¼æ— æ•ˆ, åº”ä¸º 'key:value' æ ¼å¼",
        "conf_export_invalid_format": "å¯¼å‡ºé…ç½®æ ¼å¼æ— æ•ˆ, åº”ä¸º 'key:value' æ ¼å¼",
        "conf_import_file_not_found": "æœªæ‰¾åˆ°å¯¼å…¥é…ç½®æ–‡ä»¶: {{file_path}}",
        "conf_export_file_not_found": "æœªæ‰¾åˆ°å¯¼å‡ºé…ç½®æ–‡ä»¶: {{file_path}}",
        "conf_import_file_empty": "å¯¼å…¥é…ç½®æ–‡ä»¶ä¸ºç©º: {{file_path}}",
        "conf_export_file_empty": "å¯¼å‡ºé…ç½®æ–‡ä»¶ä¸ºç©º: {{file_path}}",
        "generated_shell_script": "ç”Ÿæˆçš„ Shell è„šæœ¬",
        "confirm_execute_shell_script": "æ‚¨è¦æ‰§è¡Œæ­¤ shell è„šæœ¬å—ï¼Ÿ",
        "shell_script_not_executed": "Shell è„šæœ¬æœªæ‰§è¡Œ",
        "config_validation_error": "é…ç½®éªŒè¯é”™è¯¯: {{error}}",
        "invalid_boolean_value": "å€¼ '{{value}}' ä¸æ˜¯æœ‰æ•ˆçš„å¸ƒå°”å€¼(true/false)",
        "invalid_integer_value": "å€¼ '{{value}}' ä¸æ˜¯æœ‰æ•ˆçš„æ•´æ•°",
        "invalid_float_value": "å€¼ '{{value}}' ä¸æ˜¯æœ‰æ•ˆçš„æµ®ç‚¹æ•°",
        "invalid_type_value": "å€¼ '{{value}}' ä¸æ˜¯æœ‰æ•ˆçš„ç±»å‹ (æœŸæœ›: {{types}})",
        "value_out_of_range": "å€¼ {value} è¶…å‡ºå…è®¸èŒƒå›´({min}~{max})",
        "invalid_choice": "å€¼ '{value}' ä¸åœ¨å…è®¸é€‰é¡¹ä¸­({allowed})",
        "unknown_config_key": "æœªçŸ¥çš„é…ç½®é¡¹ '{key}'",
        "model_not_found": "æ¨¡å‹ '{model}' æœªåœ¨ models.yml ä¸­é…ç½®",
        "required_without_default": "é…ç½®é¡¹ '{key}' éœ€è¦æ˜ç¡®è®¾ç½®å€¼",
        "auto_command_action_break": "å‘½ä»¤ {{command}} æ‰§è¡Œå¤±è´¥ï¼ˆè·å–åˆ°äº† {{action}} çš„ç»“æœï¼‰ï¼Œæ— æ³•è·å¾—ä»»ä½•ç»“æœ,è¯·é‡è¯•",
        "auto_command_break": "è‡ªåŠ¨å‘½ä»¤æ‰§è¡Œå¤±è´¥: {{command}}",
        "auto_command_executing": "\n\n============= æ­£åœ¨æ‰§è¡ŒæŒ‡ä»¤: {{command}} =============\n\n",
        "model_provider_select_title": "é€‰æ‹©æ¨¡å‹ä¾›åº”å•†",
        "auto_config_analyzing": "æ­£åœ¨åˆ†æé…ç½®...",
        "config_delete_success": "æˆåŠŸåˆ é™¤é…ç½®: {{key}}",
        "config_not_found": "æœªæ‰¾åˆ°é…ç½®: {{key}}",
        "config_invalid_format": "é…ç½®æ ¼å¼æ— æ•ˆï¼Œåº”ä¸º'key:value'æ ¼å¼",
        "config_value_empty": "é…ç½®å€¼ä¸èƒ½ä¸ºç©º",
        "config_set_success": "æˆåŠŸè®¾ç½®é…ç½®: {{key}} = {{value}}",
        "model_provider_select_text": "è¯·é€‰æ‹©æ‚¨çš„æ¨¡å‹ä¾›åº”å•†ï¼š",
        "model_provider_volcano": "ç«å±±æ–¹èˆŸ",
        "model_provider_siliconflow": "ç¡…åŸºæµåŠ¨",
        "model_provider_deepseek": "DeepSeekå®˜æ–¹",        
        "model_provider_api_key_title": "APIå¯†é’¥",
        "model_provider_volcano_api_key_text": "è¯·è¾“å…¥æ‚¨çš„ç«å±±æ–¹èˆŸAPIå¯†é’¥ï¼š",
        "model_provider_volcano_r1_text": "è¯·è¾“å…¥æ‚¨çš„ç«å±±æ–¹èˆŸ R1 æ¨ç†ç‚¹(æ ¼å¼å¦‚: ep-20250204215011-vzbsg)ï¼š",
        "model_provider_volcano_v3_text": "è¯·è¾“å…¥æ‚¨çš„ç«å±±æ–¹èˆŸ V3 æ¨ç†ç‚¹(æ ¼å¼å¦‚: ep-20250204215011-vzbsg)ï¼š",
        "model_provider_siliconflow_api_key_text": "è¯·è¾“å…¥æ‚¨çš„ç¡…åŸºæµåŠ¨APIå¯†é’¥ï¼š",
        "model_provider_deepseek_api_key_text": "è¯·è¾“å…¥æ‚¨çš„DeepSeek APIå¯†é’¥ï¼š",
        "model_provider_selected": "ä¾›åº”å•†é…ç½®å·²æˆåŠŸå®Œæˆï¼åç»­ä½ å¯ä»¥ä½¿ç”¨ /models å‘½ä»¤ï¼ŒæŸ¥çœ‹ï¼Œæ–°å¢å’Œä¿®æ”¹æ‰€æœ‰æ¨¡å‹",
        "model_provider_success_title": "æˆåŠŸ",
        "index_file_filtered": "æ–‡ä»¶ {{file_path}} è¢«æ¨¡å‹ {{model_name}} çš„è®¿é—®é™åˆ¶è¿‡æ»¤",
        "models_no_active": "æœªæ‰¾åˆ°æ¿€æ´»çš„æ¨¡å‹",
        "models_speed_test_results": "æ¨¡å‹é€Ÿåº¦æµ‹è¯•ç»“æœ",
        "models_testing": "æ­£åœ¨æµ‹è¯•æ¨¡å‹: {{name}}...",
        "models_testing_start": "å¼€å§‹å¯¹æ‰€æœ‰æ¿€æ´»çš„æ¨¡å‹è¿›è¡Œé€Ÿåº¦æµ‹è¯•...",
        "generation_cancelled": "[å·²ä¸­æ–­] ç”Ÿæˆå·²å–æ¶ˆ",
        "model_not_found": "æœªæ‰¾åˆ°æ¨¡å‹: {{model_name}}",
        "generating_shell_script": "æ­£åœ¨ç”Ÿæˆ Shell è„šæœ¬",
        "new_session_started": "æ–°ä¼šè¯å·²å¼€å§‹ã€‚ä¹‹å‰çš„èŠå¤©å†å²å·²å­˜æ¡£ã€‚",
        "memory_save_success": "âœ… å·²ä¿å­˜åˆ°æ‚¨çš„è®°å¿†ä¸­",
        "file_decode_error": "æ— æ³•è§£ç æ–‡ä»¶: {{file_path}}ã€‚å°è¯•çš„ç¼–ç : {{encodings}}",
        "file_write_error": "æ— æ³•å†™å…¥æ–‡ä»¶: {{file_path}}. é”™è¯¯: {{error}}",
        "yaml_load_error": "åŠ è½½YAMLæ–‡ä»¶å‡ºé”™ {{yaml_file}}: {{error}}",
        "git_command_error": "Gitå‘½ä»¤æ‰§è¡Œé”™è¯¯: {{error}}",
        "get_commit_diff_error": "è·å–commit diffæ—¶å‡ºé”™: {{error}}",
        "no_latest_commit": "æ— æ³•è·å–æœ€æ–°çš„æäº¤ä¿¡æ¯",
        "code_review_error": "ä»£ç å®¡æŸ¥è¿‡ç¨‹å‡ºé”™: {{error}}",
        "index_file_too_large": "âš ï¸ æ–‡ä»¶ {{ file_path }} è¿‡å¤§ ({{ file_size }} > {{ max_length }}), æ­£åœ¨åˆ†å—å¤„ç†...",
        "index_update_success": "âœ… {{ model_name }} æˆåŠŸæ›´æ–° {{ file_path }} çš„ç´¢å¼• (md5: {{ md5 }}), è€—æ—¶ {{ duration }} ç§’, è¾“å…¥tokenæ•°: {{ input_tokens }}, è¾“å‡ºtokenæ•°: {{ output_tokens }}, è¾“å…¥æˆæœ¬: {{ input_cost }}, è¾“å‡ºæˆæœ¬: {{ output_cost }}",
        "index_build_error": "âŒ {{ model_name }} æ„å»º {{ file_path }} ç´¢å¼•æ—¶å‡ºé”™: {{ error }}",
        "index_build_summary": "ğŸ“Š æ€»æ–‡ä»¶æ•°: {{ total_files }}, éœ€è¦æ„å»ºç´¢å¼•: {{ num_files }}",
        "building_index_progress": "â³ æ­£åœ¨æ„å»ºç´¢å¼•: {{ counter }}/{{ num_files }}...",
        "index_source_dir_mismatch": "âš ï¸ æºç›®å½•ä¸åŒ¹é… (æ–‡ä»¶è·¯å¾„: {{ file_path }}, æºç›®å½•: {{ source_dir }})",
        "index_related_files_fail": "âš ï¸ æ— æ³•ä¸ºå— {{ chunk_count }} æ‰¾åˆ°ç›¸å…³æ–‡ä»¶",
        "index_threads_completed": "âœ… å·²å®Œæˆ {{ completed_threads }}/{{ total_threads }} ä¸ªçº¿ç¨‹",
        "index_related_files_fail": "âš ï¸ æ— æ³•ä¸ºå— {{ chunk_count }} æ‰¾åˆ°ç›¸å…³æ–‡ä»¶",
        "index_file_removed": "ğŸ—‘ï¸ å·²ç§»é™¤ä¸å­˜åœ¨çš„æ–‡ä»¶ç´¢å¼•ï¼š{{ file_path }}",
        "index_file_saved": "ğŸ’¾ å·²ä¿å­˜ç´¢å¼•æ–‡ä»¶ï¼Œæ›´æ–°äº† {{ updated_files }} ä¸ªæ–‡ä»¶ï¼Œç§»é™¤äº† {{ removed_files }} ä¸ªæ–‡ä»¶ï¼Œè¾“å…¥tokenæ•°: {{ input_tokens }}, è¾“å‡ºtokenæ•°: {{ output_tokens }}, è¾“å…¥æˆæœ¬: {{ input_cost }}, è¾“å‡ºæˆæœ¬: {{ output_cost }}",
        "human_as_model_instructions": (
            "æ‚¨ç°åœ¨å¤„äºäººç±»ä½œä¸ºæ¨¡å‹æ¨¡å¼ã€‚å†…å®¹å·²å¤åˆ¶åˆ°æ‚¨çš„å‰ªè´´æ¿ã€‚\n"
            "ç³»ç»Ÿæ­£åœ¨ç­‰å¾…æ‚¨çš„è¾“å…¥ã€‚å®Œæˆåï¼Œåœ¨æ–°è¡Œè¾“å…¥'EOF'æäº¤ã€‚\n"
            "ä½¿ç”¨'/break'é€€å‡ºæ­¤æ¨¡å¼ã€‚å¦‚æœå¤åˆ¶ç²˜è´´æœ‰é—®é¢˜ï¼Œä½¿ç”¨'/clear'æ¸…ç†å¹¶é‡æ–°ç²˜è´´ã€‚"
        ),
        "clipboard_not_supported": (
            "æœªå®‰è£…pyperclipæˆ–ä¸æ”¯æŒå‰ªè´´æ¿ï¼ŒæŒ‡ä»¤å°†ä¸ä¼šè¢«å¤åˆ¶åˆ°å‰ªè´´æ¿ã€‚"
        ),
        "human_as_model_instructions_no_clipboard": (
            "æ‚¨ç°åœ¨å¤„äºäººç±»ä½œä¸ºæ¨¡å‹æ¨¡å¼ã€‚[bold red]å†…å®¹æ— æ³•å¤åˆ¶åˆ°æ‚¨çš„å‰ªè´´æ¿ã€‚[/bold red]\n"
            "ä½†æ‚¨å¯ä»¥ä»output.txtæ–‡ä»¶å¤åˆ¶æç¤ºã€‚\n"
            "ç³»ç»Ÿæ­£åœ¨ç­‰å¾…æ‚¨çš„è¾“å…¥ã€‚å®Œæˆåï¼Œåœ¨æ–°è¡Œè¾“å…¥'EOF'æäº¤ã€‚\n"
            "ä½¿ç”¨'/break'é€€å‡ºæ­¤æ¨¡å¼ã€‚å¦‚æœå¤åˆ¶ç²˜è´´æœ‰é—®é¢˜ï¼Œä½¿ç”¨'/clear'æ¸…ç†å¹¶é‡æ–°ç²˜è´´ã€‚"
        ),
        "phase1_processing_sources": "é˜¶æ®µ 1: æ­£åœ¨å¤„ç† REST/RAG/Search æº...",
        "phase2_building_index": "é˜¶æ®µ 2: æ­£åœ¨ä¸ºæ‰€æœ‰æ–‡ä»¶æ„å»ºç´¢å¼•...",
        "phase6_file_selection": "é˜¶æ®µ 6: æ­£åœ¨å¤„ç†æ–‡ä»¶é€‰æ‹©å’Œé™åˆ¶...",
        "phase7_preparing_output": "é˜¶æ®µ 7: æ­£åœ¨å‡†å¤‡æœ€ç»ˆè¾“å‡º...",
        "chat_human_as_model_instructions": (
            "\n============= Chat å¤„äº Human as Model æ¨¡å¼ =============\n"
            "é—®é¢˜å·²å¤åˆ¶åˆ°å‰ªè´´æ¿\n"
            "è¯·ä½¿ç”¨Webç‰ˆæœ¬æ¨¡å‹è·å–ç­”æ¡ˆ\n"
            "æˆ–è€…ä½¿ç”¨ /conf human_as_model:false å…³é—­è¯¥æ¨¡å¼ç›´æ¥åœ¨ç»ˆç«¯è·å¾—ç­”æ¡ˆã€‚"
            "å°†è·å¾—ç­”æ¡ˆé»è´´åˆ°ä¸‹é¢çš„è¾“å…¥æ¡†ï¼Œæ¢è¡Œåï¼Œä½¿ç”¨ '/break' é€€å‡ºï¼Œ'/clear' æ¸…å±ï¼Œ'/eof' æäº¤ã€‚"
        ),
        "code_generation_start": "æ­£åœ¨è‡ªåŠ¨ç”Ÿæˆä»£ç ...",
        "code_generation_complete": "{{ model_names}} ä»£ç ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶ {{ duration }} ç§’ (é‡‡æ ·æ•°: {{ sampling_count }}), è¾“å…¥tokenæ•°: {{ input_tokens }}, è¾“å‡ºtokenæ•°: {{ output_tokens }}, è¾“å…¥æˆæœ¬: {{ input_cost }}, è¾“å‡ºæˆæœ¬: {{ output_cost }}, é€Ÿåº¦: {{ speed }} tokens/ç§’",
        "code_merge_start": "æ­£åœ¨è‡ªåŠ¨åˆå¹¶ä»£ç ...",
        "code_execution_warning": "å‘é€ç»™æ¨¡å‹çš„å†…å®¹é•¿åº¦ä¸º {{ content_length }} tokensï¼ˆæ‚¨å¯èƒ½æ”¶é›†äº†å¤ªå¤šæ–‡ä»¶ï¼‰ï¼Œè¶…è¿‡äº†æœ€å¤§è¾“å…¥é•¿åº¦ {{ max_length }}",
        "quick_filter_start": "{{ model_name }} å¼€å§‹æŸ¥æ‰¾ä¸Šä¸‹æ–‡(quick_filter)...",
        "normal_filter_start": "{{ model_name }} å¼€å§‹æŸ¥æ‰¾ä¸Šä¸‹æ–‡(normal_filter)...",
        "pylint_check_failed": "âš ï¸ Pylint æ£€æŸ¥å¤±è´¥: {{ error_message }}",
        "pylint_error": "âŒ è¿è¡Œ Pylint æ—¶å‡ºé”™: {{ error_message }}",
        "begin_index_source_code": "ğŸš€ å¼€å§‹ä¸º {{ source_dir }} ä¸­çš„æºä»£ç å»ºç«‹ç´¢å¼•",
        "unmerged_blocks_warning": "âš ï¸ å‘ç° {{ num_blocks }} ä¸ªæœªåˆå¹¶çš„ä»£ç å—ï¼Œæ›´æ”¹å°†ä¸ä¼šè¢«åº”ç”¨ã€‚è¯·æ‰‹åŠ¨æ£€æŸ¥åé‡è¯•ã€‚",
        "pylint_file_check_failed": "âš ï¸ {{ file_path }} çš„ Pylint æ£€æŸ¥å¤±è´¥ã€‚æ›´æ”¹æœªåº”ç”¨ã€‚é”™è¯¯: {{ error_message }}",
        "merge_success": "âœ… æˆåŠŸåˆå¹¶äº† {{ num_files }} ä¸ªæ–‡ä»¶ä¸­çš„æ›´æ”¹ {{ num_changes }}/{{ total_blocks }} ä¸ªä»£ç å—ã€‚",
        "no_changes_made": "âš ï¸ æœªå¯¹ä»»ä½•æ–‡ä»¶è¿›è¡Œæ›´æ”¹ã€‚è¿™ä¸ªåŸå› å¯èƒ½æ˜¯å› ä¸ºcodingå‡½æ•°ç”Ÿæˆçš„æ–‡æœ¬å—æ ¼å¼æœ‰é—®é¢˜ï¼Œå¯¼è‡´æ— æ³•åˆå¹¶è¿›é¡¹ç›®",
        "unmerged_blocks_title": "æœªåˆå¹¶ä»£ç å—",
        "merged_blocks_title": "åˆå¹¶çš„æ›´æ”¹",
        "unmerged_file_path": "æ–‡ä»¶: {{file_path}}",
        "unmerged_search_block": "Search Block({{similarity}}):",
        "unmerged_replace_block": "Replace Block:",
        "unmerged_blocks_total": "æœªåˆå¹¶ä»£ç å—æ•°é‡: {{num_blocks}}",
        "git_init_required": "âš ï¸ auto_merge ä»…é€‚ç”¨äº git ä»“åº“ã€‚\n\nè¯·å°è¯•åœ¨æºç›®å½•ä¸­ä½¿ç”¨ git init:\n\n```shell\ncd {{ source_dir }}\ngit init.\n```\n\nç„¶åå†æ¬¡è¿è¡Œ auto-coderã€‚\né”™è¯¯: {{ error }}",
        "quick_filter_reason": "è‡ªåŠ¨è·å–(quick_filteræ¨¡å¼)",
        "quick_filter_too_long": "âš ï¸ ç´¢å¼•æ–‡ä»¶è¿‡å¤§ ({{ tokens_len }}/{{ max_tokens }})ã€‚æŸ¥è¯¢å°†è¢«åˆ†æˆ {{ split_size }} ä¸ªéƒ¨åˆ†æ‰§è¡Œã€‚",
        "quick_filter_tokens_len": "ğŸ“Š å½“å‰ç´¢å¼•å¤§å°: {{ tokens_len }} tokens",
        "upsert_file": "âœ… æ›´æ–°æ–‡ä»¶: {{ file_path }}",
        "files_merged": "âœ… æˆåŠŸåˆå¹¶äº† {{ total }} ä¸ªæ–‡ä»¶åˆ°é¡¹ç›®ä¸­ã€‚",
        "merge_failed": "âŒ åˆå¹¶æ–‡ä»¶ {{ path }} å¤±è´¥: {{ error }}",
        "files_merged_total": "âœ… åˆå¹¶äº† {{ total }} ä¸ªæ–‡ä»¶åˆ°é¡¹ç›®ä¸­ã€‚",
        "ranking_skip": "åªæœ‰1ä¸ªå€™é€‰é¡¹ï¼Œè·³è¿‡æ’åº",
        "ranking_start": "å¼€å§‹å¯¹ {{ count }} ä¸ªå€™é€‰é¡¹è¿›è¡Œæ’åº,ä½¿ç”¨æ¨¡å‹ {{ model_name }} æ‰“åˆ†",
        "ranking_failed_request": "æ’åºè¯·æ±‚å¤±è´¥: {{ error }}",
        "ranking_all_failed": "æ‰€æœ‰æ’åºè¯·æ±‚éƒ½å¤±è´¥",
        "ranking_complete": "{{ model_names }} æ’åºå®Œæˆï¼Œè€—æ—¶ {{ elapsed }} ç§’ï¼Œæ€»æŠ•ç¥¨æ•°: {{ total_tasks }}ï¼Œæœ€ä½³å€™é€‰ç´¢å¼•: {{ best_candidate }}ï¼Œå¾—åˆ†: {{ scores }}ï¼Œè¾“å…¥tokenæ•°: {{ input_tokens }}ï¼Œè¾“å‡ºtokenæ•°: {{ output_tokens }}ï¼Œè¾“å…¥æˆæœ¬: {{ input_cost }}, è¾“å‡ºæˆæœ¬: {{ output_cost }}ï¼Œé€Ÿåº¦: {{ speed }} tokens/ç§’",
        "ranking_process_failed": "æ’åºè¿‡ç¨‹å¤±è´¥: {{ error }}",
        "ranking_failed": "æ’åºå¤±è´¥ï¼Œè€—æ—¶ {{ elapsed }} ç§’ï¼Œä½¿ç”¨åŸå§‹é¡ºåº",
        "stream_out_stats": "æ¨¡å‹: {{ model_name }},æ€»è€—æ—¶ {{ elapsed_time }} ç§’,é¦–tokenæ—¶é—´: {{ first_token_time }} ç§’, é€Ÿåº¦: {{ speed }} tokens/ç§’, è¾“å…¥tokenæ•°: {{ input_tokens }}, è¾“å‡ºtokenæ•°: {{ output_tokens }}, è¾“å…¥æˆæœ¬: {{ input_cost }}, è¾“å‡ºæˆæœ¬: {{ output_cost }}",
        "quick_filter_stats": "{{ model_names }} Quick Filter å®Œæˆè€—æ—¶ {{ elapsed_time }} ç§’ï¼Œè¾“å…¥tokenæ•°: {{ input_tokens }}, è¾“å‡ºtokenæ•°: {{ output_tokens }}, è¾“å…¥æˆæœ¬: {{ input_cost }}, è¾“å‡ºæˆæœ¬: {{ output_cost }} é€Ÿåº¦: {{ speed }} tokens/ç§’",
        "quick_filter_title": "{{ model_name }} æ­£åœ¨åˆ†æå¦‚ä½•ç­›é€‰ä¸Šä¸‹æ–‡...",
        "quick_filter_failed": "âŒ å¿«é€Ÿè¿‡æ»¤å™¨å¤±è´¥: {{ error }}. ",
        "estimated_chat_input_tokens": "å¯¹è¯è¾“å…¥tokené¢„ä¼°ä¸º: {{ estimated_input_tokens }}",
        "estimated_input_tokens_in_generate": "ç”Ÿæˆä»£ç ({{ generate_mode }})é¢„è®¡è¾“å…¥tokenæ•°: {{ estimated_input_tokens_in_generate }}",        
        "model_has_access_restrictions": "{{model_name}} æœ‰è®¿é—®é™åˆ¶ï¼Œæ— æ³•ä½¿ç”¨å½“å‰åŠŸèƒ½",
        "auto_command_not_found": "æœªæ‰¾åˆ°è‡ªåŠ¨å‘½ä»¤: {{command}}ã€‚è¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥å¹¶é‡è¯•ã€‚",
        "auto_command_failed": "è‡ªåŠ¨å‘½ä»¤æ‰§è¡Œå¤±è´¥: {{error}}ã€‚è¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥å¹¶é‡è¯•ã€‚",
        "command_execution_result": "{{action}} æ‰§è¡Œç»“æœ",
        "satisfied_prompt": "å·²æ»¡è¶³éœ€æ±‚ï¼Œæ— éœ€è¿›ä¸€æ­¥æ“ä½œ",
        "auto_command_analyzed": "è¢«é€‰æ‹©æŒ‡ä»¤",
        "invalid_enum_value": "å€¼ '{{value}}' ä¸åœ¨å…è®¸çš„å€¼åˆ—è¡¨ä¸­ ({{allowed}})",
        "conversation_pruning_start": "âš ï¸ å¯¹è¯é•¿åº¦ {{total_tokens}} tokens è¶…è¿‡å®‰å…¨é˜ˆå€¼ {{safe_zone}}ï¼Œå¼€å§‹ä¿®å‰ªå¯¹è¯ã€‚",
        "invalid_file_number": "âš ï¸ æ— æ•ˆçš„æ–‡ä»¶ç¼–å· {{file_number}}ï¼Œæ€»æ–‡ä»¶æ•°ä¸º {{total_files}}",        
        "all_merge_results_failed": "âš ï¸ æ‰€æœ‰åˆå¹¶å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå€™é€‰",
        "only_one_merge_result_success": "âœ… åªæœ‰ä¸€ä¸ªåˆå¹¶ç»“æœæˆåŠŸï¼Œè¿”å›è¯¥å€™é€‰",
        "index_export_success": "ç´¢å¼•å¯¼å‡ºæˆåŠŸ: {{path}}",
        "index_import_success": "ç´¢å¼•å¯¼å…¥æˆåŠŸ: {{path}}",
        "edits_title": "ç¼–è¾‘å—",
        "diff_blocks_title": "å·®å¼‚å—",
        "index_exclude_files_error": "ç´¢å¼•æ’é™¤æ–‡ä»¶æ—¶å‡ºé”™: {{error}}",
        "rank_code_modification_title": "æ¨¡å‹{{model_name}}å¯¹ä»£ç æ‰“åˆ†",
        "sorted_files_message": "é‡æ–°æ’åºåçš„æ–‡ä»¶è·¯å¾„:\n{% for file in files %}- {{ file }}\n{% endfor %}",
        "estimated_input_tokens_in_ranking": "æ’åºé¢„è®¡è¾“å…¥tokenæ•°: {{ estimated_input_tokens }}",
        "file_snippet_procesed": "æ–‡ä»¶ {{ file_path }} å¤„ç†åtokenæ•°: {{ tokens }} => {{ snippet_tokens }} å½“å‰æ€»tokenæ•°: {{ total_tokens }}",
        "tool_ask_user": "æ‚¨çš„å›å¤: ",
        "tool_ask_user_accept":"æ”¶åˆ°æ‚¨çš„å›å¤",
    }}


def get_system_language():
    try:
        return locale.getdefaultlocale()[0][:2]
    except:
        return 'en'


def get_message(key):
    lang = get_system_language()
    return MESSAGES.get(lang, MESSAGES['en']).get(key, MESSAGES['en'][key])


def get_message_with_format(msg_key: str, **kwargs):
    return format_str_jinja2(get_message(msg_key), **kwargs)
